version: "3.0"
services:
  llamacpp:
    image: llama-cpp-gguf 
    container_name: llamacpp
    platform: linux/arm64
    ports:
      - 8080:8080
    command: --server -m /models/gemma-2b.gguf -ngl 100 -c 512 -p 8080 --host 0.0.0.0
    volumes:
      - "./models:/models"

  modulesapi:
    image: test-api
    container_name: modulesapi
    platform: linux/arm64
    ports:
      - 8000:8000
